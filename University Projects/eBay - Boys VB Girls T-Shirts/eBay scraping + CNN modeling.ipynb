{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning for Image Classification- Boys vs Girls Shirts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We  try to classify an unseen shirt image as being of \"boys\" or of \"girls\".  we're going to use Convolutional Neural Networks.\n",
    "\n",
    "    But first, we need to get the files from Ebay website:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "import sys\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import transform, color, img_as_ubyte\n",
    "from os import listdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_image(url, title, file_name):\n",
    "    try:\n",
    "        response = requests.get(url)    \n",
    "    except:\n",
    "        return '', ''\n",
    "    with open(file_name, \"wb\") as file:\n",
    "        file.write(response.content)\n",
    "    return title, file_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "open folders for the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir boys\n",
    "!mkdir girls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import boys images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boys_url = 'https://il.ebay.com/b/Boys-Short-Sleeve-Sleeve-Tops-T-Shirts-Sizes-4-Up/175521/bn_4278610?rt=nc&LH_ItemCondition=1000&LH_BIN=1&LH_PrefLoc=3&_pgn='\n",
    "max_pages = 40\n",
    "boys_items_data = {'title': {}, 'file_id': {}}\n",
    "f = IntProgress(min = 0, max = max_pages)\n",
    "display(f)\n",
    "all_items_counter = 0\n",
    "\n",
    "for page_num in range(max_pages):\n",
    "    url = boys_url + str(page_num)\n",
    "    try:\n",
    "        r = requests.get(url, \"lxml\")\n",
    "    except:\n",
    "        print('Stopped at page: ' + page_num)\n",
    "        break\n",
    "    soup = BeautifulSoup(r.content)\n",
    "    images = soup.find_all('img')[1:]\n",
    "    image_titles = [img['alt'] for img in images]\n",
    "    image_files_src = [img['src'] for img in images]\n",
    "    image_files_datasrc = [img.get('data-src', None) for img in images]\n",
    "    image_files = [src if datasrc is None else datasrc for src, datasrc in zip(image_files_src, image_files_datasrc)]\n",
    "           \n",
    "    for i in range(len(images)):\n",
    "        title, file_name = download_image(image_files[i], image_titles[i], './boys/' + str(all_items_counter + i) + '.jpg')\n",
    "        boys_items_data['title'][all_items_counter + i] = title\n",
    "        boys_items_data['file_id'][all_items_counter + i] = all_items_counter + i\n",
    "    all_items_counter += len(images)\n",
    "    f.value += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import girls images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "girls_url = 'https://il.ebay.com/b/Girls-Short-Sleeve-Sleeve-Tops-T-Shirts-Sizes-4-Up/175529/bn_4741026?rt=nc&LH_ItemCondition=1000&LH_BIN=1&LH_PrefLoc=3&_pgn='\n",
    "max_pages = 40\n",
    "girls_items_data = {'title': {}, 'file_id': {}}\n",
    "f = IntProgress(min = 0, max = max_pages)\n",
    "display(f)\n",
    "all_items_counter = 0\n",
    "\n",
    "for page_num in range(max_pages):\n",
    "    url = girls_url + str(page_num)\n",
    "    try:\n",
    "        r = requests.get(url, \"lxml\")\n",
    "    except:\n",
    "        print('Stopped at page: ' + page_num)\n",
    "        break\n",
    "    soup = BeautifulSoup(r.content)\n",
    "    images = soup.find_all('img')[1:]\n",
    "    image_titles = [img['alt'] for img in images]\n",
    "    image_files_src = [img['src'] for img in images]\n",
    "    image_files_datasrc = [img.get('data-src', None) for img in images]\n",
    "    image_files = [src if datasrc is None else datasrc for src, datasrc in zip(image_files_src, image_files_datasrc)]\n",
    "           \n",
    "    for i in range(len(images)):\n",
    "        title, file_name = download_image(image_files[i], image_titles[i], './girls/' + str(all_items_counter + i) + '.jpg')\n",
    "        girls_items_data['title'][all_items_counter + i] = title\n",
    "        girls_items_data['file_id'][all_items_counter + i] = all_items_counter + i\n",
    "    all_items_counter += len(images)\n",
    "    f.value += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "girls_df = pd.DataFrame(girls_items_data)\n",
    "boys_df = pd.DataFrame(boys_items_data)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "boys_train, boys_test = train_test_split(boys_df, test_size=0.2)\n",
    "girls_train, girls_test = train_test_split(girls_df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets start to work on the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def get_file_list(df, folder, n_sample = None, seed = None):\n",
    "    if n_sample is None:\n",
    "        file_ids_list = df.file_id.values\n",
    "    else:\n",
    "        file_ids_list = df.sample(n = n_sample, random_state = seed).file_id.values\n",
    "    files_list = [folder + '/' + str(file_id) + '.jpg' for file_id in file_ids_list]\n",
    "    return files_list\n",
    "\n",
    "def read_image_and_resize(f, w = 100, h = 100):\n",
    "    img = plt.imread(f)\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        img = transform.resize(img, (w, h), mode='constant')\n",
    "        img = img_as_ubyte(img)\n",
    "    img = color.gray2rgb(img)\n",
    "    img = img[np.newaxis, :, :, :3]\n",
    "    if img.shape != (1, 100, 100, 3):\n",
    "        raise ValueError(f + str(img.shape))\n",
    "    return img\n",
    "\n",
    "def read_images_4d_array(files_list):\n",
    "    images_list = [read_image_and_resize(file) for file in files_list]\n",
    "    images_array = np.concatenate(images_list)\n",
    "    return images_array\n",
    "\n",
    "def get_images_matrix(df, folder, n = None, seed = 1976):\n",
    "    files_list = get_file_list(df, folder, n, seed)\n",
    "    images = read_images_4d_array(files_list)\n",
    "    return images, files_list\n",
    "\n",
    "def get_all_pixels(x):\n",
    "    return x.reshape(-1, np.prod(x.shape[1:]))\n",
    "\n",
    "def numpy_array_size_in_bytes(a):\n",
    "    return a.size * a.itemsize\n",
    "\n",
    "def shape_and_size(x, name):\n",
    "    n_rows = x.shape[0]\n",
    "    if len(x.shape) == 1:\n",
    "        n_cols = 1\n",
    "    elif len(x.shape) == 2:\n",
    "        n_cols = x.shape[1]\n",
    "    else:\n",
    "        warnings.warn('Function is meaningful for 1 or 2-D numpy arrays, taking 2nd dimension as n_cols')\n",
    "        n_cols = x.shape[1]        \n",
    "    size = numpy_array_size_in_bytes(x)\n",
    "    print('%s Shape: %d X %d, Size (bytes): %d' % (name, n_rows, n_cols, size))\n",
    "\n",
    "def conf_matrix(y_true, y_pred):\n",
    "    return pd.crosstab(y_true, y_pred, rownames=['True'], colnames=['Predicted'], margins=True)\n",
    "\n",
    "def get_final_matrices(n_train = None, n_test = None):\n",
    "    folder = 'C:/Users/chen/Downloads/boys girls shirts/'\n",
    "    x_boys_train, boys_train_files = get_images_matrix(boys_train, folder + 'boys', n_train)\n",
    "    x_boys_test, boys_test_files = get_images_matrix(boys_test, folder + 'boys', n_test)\n",
    "    x_girls_train, girls_train_files = get_images_matrix(girls_train, folder + 'girls', n_train)\n",
    "    x_girls_test, girls_test_files = get_images_matrix(girls_test, folder + 'girls', n_test)\n",
    "    \n",
    "    x_boys_train_all = get_all_pixels(x_boys_train)\n",
    "    x_boys_test_all = get_all_pixels(x_boys_test)\n",
    "    x_girls_train_all = get_all_pixels(x_girls_train)\n",
    "    x_girls_test_all = get_all_pixels(x_girls_test)\n",
    "\n",
    "    x_train = np.vstack([x_boys_train_all, x_girls_train_all])\n",
    "    x_test = np.vstack([x_boys_test_all, x_girls_test_all])\n",
    "\n",
    "    y_boys_train = np.array([np.uint8(0)] * x_boys_train.shape[0])\n",
    "    y_boys_test = np.array([np.uint8(0)] * x_boys_test.shape[0])\n",
    "    y_girls_train = np.array([np.uint8(1)] * x_girls_train.shape[0])\n",
    "    y_girls_test = np.array([np.uint8(1)] * x_girls_test.shape[0])\n",
    "    y_train = np.concatenate([y_boys_train, y_girls_train])\n",
    "    y_test = np.concatenate([y_boys_test, y_girls_test])\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = get_final_matrices()\n",
    "\n",
    "shape_and_size(x_train, 'x_train')\n",
    "shape_and_size(x_test, 'x_test')\n",
    "shape_and_size(y_train, 'y_train')\n",
    "shape_and_size(y_test, 'y_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our platform of choice [Keras](https://keras.io/) accepts `x_train` of type `float`. It's best to turn it to float in the 0-1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Here Keras needs the original 4D shape of the images array, so we `reshape` them to be of dimensions [N images X Height X Width X N channels].\n",
    "    We're using a `Conv2D` layer of 32 units and a 3x3 kernel, then a 64 units layer also with a 3x3 kernel, followed by a `MaxPooling2D` with a 2xs pool size layer and a 25% `Dropout`. The output is then `Flatten`ed and connected to a `Dense` layer of 128 neurons, another 50% `Dropout` and then a single neuron with a `sigmoid` activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 10\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "img_rows, img_cols, channels = 100, 100, 3\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, channels)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, channels)\n",
    "input_shape = (img_rows, img_cols, channels)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(x_test, y_test))\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got a test accuracy of ~84%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc = 'upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
